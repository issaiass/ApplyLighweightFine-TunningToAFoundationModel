{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c1ee4f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/student/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9017d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (4.40.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\denys\\anaconda3\\envs\\genai\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcd2e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.29.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.14.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (0.20.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (13.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: responses, evaluate\n",
      "\u001b[33m  WARNING: The script evaluate-cli is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.1 responses-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d40cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, AutoPeftModelForCausalLM\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer, Trainer,\n",
    "                          AutoModelForSequenceClassification, TrainingArguments,\n",
    "                          DataCollatorWithPadding\n",
    "                         )\n",
    "from datasets import load_dataset, load_metric\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset.\n",
    "\n",
    "[Distilbert for Sequence Classification](https://huggingface.co/transformers/v3.1.0/custom_datasets.html?highlight=forsequenceclassification#seq-imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'test']\n",
    "ds = {split: ds for split ,ds in zip(splits, load_dataset('imdb', split=splits))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3509bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 500\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 500\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(500))\n",
    "    \n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2948045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Let's use a lambda function to tokenize all the examples\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = ds[split].map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True)\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# dictionaries for labels\n",
    "id2label = {0:'NEGATIVE', 1:'POSITIVE'}\n",
    "label2id = dict(zip(id2label.values(), id2label.keys()))\n",
    "\n",
    "# foundation model to evaluate\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# configuration for the tokenizer in the model\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab7b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just test the dataset\n",
    "tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78892d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 17:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.900400</td>\n",
       "      <td>0.712684</td>\n",
       "      <td>0.474000</td>\n",
       "      <td>0.643148</td>\n",
       "      <td>0.482688</td>\n",
       "      <td>0.963415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.8583055725097656, metrics={'train_runtime': 1077.6704, 'train_samples_per_second': 0.464, 'train_steps_per_second': 0.116, 'total_flos': 136488765947904.0, 'train_loss': 0.8583055725097656, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation metric and data collation\n",
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# metric evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./foundation-model-results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='logs',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=100,\n",
    "    warmup_ratio=0.1\n",
    ")\n",
    "\n",
    "# perform training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660bbaad-4922-4334-a1ea-5847ddfad126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT2</th>\n",
       "      <td>0.712684</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.643148</td>\n",
       "      <td>0.482688</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>184.8182</td>\n",
       "      <td>2.705</td>\n",
       "      <td>0.676</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "GPT2   0.712684          0.474  0.643148        0.482688     0.963415   \n",
       "\n",
       "      eval_runtime  eval_samples_per_second  eval_steps_per_second  epoch  \n",
       "GPT2      184.8182                    2.705                  0.676    1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate foundation model\n",
    "foundation_model_evaluation = trainer.evaluate()\n",
    "foundation_df = pd.DataFrame([foundation_model_evaluation], index=['GPT2'])\n",
    "foundation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c8e6d",
   "metadata": {},
   "source": [
    "### View the results\n",
    "\n",
    "Let's look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b61e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with the predictions and the text and the labels\n",
    "items_for_manual_review = tokenized_dataset[\"test\"].select([0, 1, 22, 31, 43, 292, 448, 487])\n",
    "results = trainer.predict(items_for_manual_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8542ea57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;When I unsuspectedly rented A Thou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the latest entry in the long series of...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the early 00's, production companies had a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is just one of those films which cannot j...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really liked the movie 'The Emporer's New Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I picked out this DVD out of the cheepo bin at...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What a waste of time to watch this movie. Poor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When this show first aired I will admit to bei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  predictions  labels\n",
       "0  <br /><br />When I unsuspectedly rented A Thou...            0       1\n",
       "1  This is the latest entry in the long series of...            1       1\n",
       "2  In the early 00's, production companies had a ...            1       0\n",
       "3  This is just one of those films which cannot j...            1       0\n",
       "4  I really liked the movie 'The Emporer's New Gr...            1       0\n",
       "5  I picked out this DVD out of the cheepo bin at...            1       0\n",
       "6  What a waste of time to watch this movie. Poor...            1       0\n",
       "7  When this show first aired I will admit to bei...            1       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [item[\"text\"] for item in items_for_manual_review],\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82892949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# foundation model to do peft\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# configuration for the tokenizer in the model\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# peft configuration\n",
    "lora_config = LoraConfig(\n",
    "    fan_in_fan_out=False,\n",
    "    init_lora_weights=True,\n",
    "    layers_pattern=None,\n",
    "    layers_to_transform=None,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    modules_to_save=None,\n",
    "    peft_type='LORA',\n",
    "    r=8,\n",
    "    revision=None,\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1c3dbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,736,256 || trainable%: 0.236428452686603\n"
     ]
    }
   ],
   "source": [
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc190e23-aa98-46ea-a15b-d956008e1bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 17:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.606800</td>\n",
       "      <td>0.341798</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.884921</td>\n",
       "      <td>0.864341</td>\n",
       "      <td>0.906504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.5577400207519532, metrics={'train_runtime': 1045.6772, 'train_samples_per_second': 0.478, 'train_steps_per_second': 0.12, 'total_flos': 136962000617472.0, 'train_loss': 0.5577400207519532, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation metric and data collation\n",
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-model-results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='lora-logs',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=100,\n",
    "    warmup_ratio=0.1\n",
    ")\n",
    "\n",
    "# perform training\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b524d1e2-4184-49e1-97c3-d327c33df1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 03:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT2-LoRA</th>\n",
       "      <td>0.341798</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.884921</td>\n",
       "      <td>0.864341</td>\n",
       "      <td>0.906504</td>\n",
       "      <td>224.0936</td>\n",
       "      <td>2.231</td>\n",
       "      <td>0.558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "GPT2-LoRA   0.341798          0.884  0.884921        0.864341     0.906504   \n",
       "\n",
       "           eval_runtime  eval_samples_per_second  eval_steps_per_second  epoch  \n",
       "GPT2-LoRA      224.0936                    2.231                  0.558    1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get lora evaluations\n",
    "lora_evaluation = trainer.evaluate()\n",
    "\n",
    "# view metrics\n",
    "lora_df = pd.DataFrame([lora_evaluation], index=['GPT2-LoRA'])\n",
    "lora_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "051268a6-fe59-4316-bb71-ac6d8af45a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"issaiass/gpt2-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22ef7d7c-dfa8-431e-ac13-74fbfd6f2439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "pretrained_lora_config = PeftConfig.from_pretrained(\"issaiass/gpt2-lora\")\n",
    "pretrained_model = AutoModelForSequenceClassification.from_pretrained(pretrained_lora_config.base_model_name_or_path)\n",
    "pretrained_lora_model = PeftModel.from_pretrained(pretrained_model, \"issaiass/gpt2-lora\")\n",
    "\n",
    "lora_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "lora_tokenizer.pad_token = lora_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be2d8778-4a94-4fb9-b66d-c2f605f83e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE',\n",
       "  'probabilities': [0.09818808734416962, 0.901811957359314]},\n",
       " {'label': 'NEGATIVE',\n",
       "  'probabilities': [0.8778833150863647, 0.12211669981479645]},\n",
       " {'label': 'POSITIVE',\n",
       "  'probabilities': [0.22314785420894623, 0.7768521308898926]},\n",
       " {'label': 'NEGATIVE',\n",
       "  'probabilities': [0.8513521552085876, 0.14864780008792877]},\n",
       " {'label': 'POSITIVE',\n",
       "  'probabilities': [0.2490847408771515, 0.7509152293205261]},\n",
       " {'label': 'NEGATIVE',\n",
       "  'probabilities': [0.8931923508644104, 0.1068076565861702]},\n",
       " {'label': 'NEGATIVE',\n",
       "  'probabilities': [0.7280558943748474, 0.271944135427475]}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "def lora_predict(sentence:str):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = lora_tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "    inputs.to(device)\n",
    "    lora_model.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = lora_model(input_ids=inputs['input_ids'])\n",
    "        logits = outputs.logits\n",
    "        logits.to(device)\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1).cpu()\n",
    "    predicted_class_id = probabilities.argmax(dim=1).cpu().numpy().tolist()\n",
    "    probabilities = probabilities.numpy().tolist()\n",
    "    predicted_label = [id2label[cid] for cid in predicted_class_id]\n",
    "\n",
    "    json_data = [{\"label\": lbl, \"probabilities\": prob} for lbl, prob in zip(predicted_label, probabilities) ]\n",
    "    json_string = json.dumps(json_data, indent=4)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "lora_predict(\n",
    "    sentence=\n",
    "    [\"Nora Roberts is the most prolific romance writer the world has ever known.\", \n",
    "     \"That's no way to talk to a hero!\",\n",
    "     \"Everybody loves Mary, she's addorable\",\n",
    "     \"I do not like it so much\",\n",
    "     \"Messi and Cristiano are the best football players in the world\",\n",
    "     \"Is not feasible to put all your money in bitcoins\",\n",
    "     \"Tomorrow never dies\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22a8e2-81b5-4c20-927a-8b01302ca514",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09d2aa8e-cf5d-4092-a590-3d0f27f2bc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT2</th>\n",
       "      <td>0.712684</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.643148</td>\n",
       "      <td>0.482688</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>184.8182</td>\n",
       "      <td>2.705</td>\n",
       "      <td>0.676</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2-LoRA</th>\n",
       "      <td>0.341798</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.884921</td>\n",
       "      <td>0.864341</td>\n",
       "      <td>0.906504</td>\n",
       "      <td>224.0936</td>\n",
       "      <td>2.231</td>\n",
       "      <td>0.558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "GPT2        0.712684          0.474  0.643148        0.482688     0.963415   \n",
       "GPT2-LoRA   0.341798          0.884  0.884921        0.864341     0.906504   \n",
       "\n",
       "           eval_runtime  eval_samples_per_second  eval_steps_per_second  epoch  \n",
       "GPT2           184.8182                    2.705                  0.676    1.0  \n",
       "GPT2-LoRA      224.0936                    2.231                  0.558    1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([foundation_df, lora_df])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
